import os
import uuid
import json
import mimetypes
import base64
import requests
import re
from urllib.parse import quote, urljoin
from PIL import Image
import io
try:
    import PyPDF2
except ImportError:
    PyPDF2 = None
try:
    import docx
except ImportError:
    docx = None
try:
    from bs4 import BeautifulSoup
except ImportError:
    BeautifulSoup = None
from flask import Flask, request, jsonify, send_from_directory, session
from flask_cors import CORS
try:
    from huggingface_hub import InferenceClient
except ImportError:
    InferenceClient = None
from dotenv import load_dotenv # Importe esta linha para carregar vari√°veis de ambiente

# --- CARREGA VARI√ÅVEIS DE AMBIENTE ---
# Isso deve estar no topo do seu arquivo app.py, antes de usar os.getenv para as chaves
load_dotenv() 

# --- INICIALIZA√á√ÉO DO FLASK ---
app = Flask(__name__)

# Permite apenas o dom√≠nio do GitHub Pages do seu projeto e o endere√ßo do backend Render
CORS(app, supports_credentials=True, origins=[
    "https://jonathan0078.github.io",
    "https://aemi.onrender.com"
])

# Carrega as chaves da aplica√ß√£o a partir de vari√°veis de ambiente
FLASK_SECRET_KEY = os.getenv("FLASK_SECRET_KEY", "dev-key-change-in-production")
HUGGING_FACE_TOKEN = os.getenv("HF_TOKEN")
# NOVAS VARI√ÅVEIS PARA GOOGLE CUSTOM SEARCH
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GOOGLE_CSE_ID = os.getenv("GOOGLE_CSE_ID", "f1582494ef7894395") # CX ID que voc√™ forneceu

# Valida√ß√£o das chaves
if not HUGGING_FACE_TOKEN:
    print("AVISO: Token da Hugging Face n√£o configurado. Chat com IA n√£o funcionar√°.")
    print("Configure a vari√°vel de ambiente HF_TOKEN no Replit.")

if not GOOGLE_API_KEY:
    print("AVISO: GOOGLE_API_KEY n√£o configurada. Funcionalidade de busca web pode n√£o funcionar.")
    print("Configure as vari√°veis GOOGLE_API_KEY e GOOGLE_CSE_ID no Replit Secrets.")

if not GOOGLE_CSE_ID or GOOGLE_CSE_ID == "f1582494ef7894395":
    print("AVISO: GOOGLE_CSE_ID usando valor padr√£o. Configure seu pr√≥prio CSE ID.")

app.secret_key = FLASK_SECRET_KEY

# --- CONFIGURA√á√ïES DA BASE DE CONHECIMENTO ---
KB_DIR = os.path.join(os.path.dirname(__file__), 'knowledge_base')
KB_DB = os.path.join(KB_DIR, 'kb_data.json')
os.makedirs(KB_DIR, exist_ok=True)

def load_kb():
    if not os.path.exists(KB_DB):
        return []
    try:
        with open(KB_DB, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"Erro ao carregar KB: {e}")
        return []

def save_kb(data):
    try:
        with open(KB_DB, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Erro ao salvar KB: {e}")

# --- FUN√á√ÉO DE BUSCA NA INTERNET ---
def google_search_api(query, num_results=3):
    """
    Faz uma busca na web usando a Google Custom Search JSON API.
    """
    if not GOOGLE_API_KEY or not GOOGLE_CSE_ID:
        print("Erro: Chave de API do Google ou CSE ID n√£o configurados. Retornando resultados vazios.")
        return {"error": "API do Google n√£o configurada"}

    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        "key": GOOGLE_API_KEY,
        "cx": GOOGLE_CSE_ID,
        "q": query,
        "num": min(num_results, 10),  # Google limita a 10 resultados por requisi√ß√£o
        "safe": "active"  # Filtro de conte√∫do seguro
    }

    try:
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        search_results = response.json()

        results_list = []
        if "items" in search_results:
            for item in search_results["items"]:
                results_list.append({
                    "title": item.get("title", "Sem t√≠tulo"),
                    "link": item.get("link", ""),
                    "snippet": item.get("snippet", "Sem descri√ß√£o")
                })
        
        return {"results": results_list, "query": query}
    except requests.exceptions.RequestException as e:
        print(f"Erro na requisi√ß√£o √† API de busca do Google: {e}")
        return {"error": f"Erro na requisi√ß√£o: {str(e)}"}
    except Exception as e:
        print(f"Erro inesperado ao processar busca do Google: {e}")
        return {"error": f"Erro inesperado: {str(e)}"}

# --- ROTA PARA TESTAR A BUSCA DO GOOGLE ---
@app.route('/api/search', methods=['GET'])
def perform_search():
    query = request.args.get('q', '')
    if not query:
        return jsonify({"error": "Par√¢metro 'q' (query) √© obrigat√≥rio."}), 400
    
    num_results = int(request.args.get('num', 5))
    results = google_search_api(query, num_results)
    return jsonify(results)

# --- ROTAS DA BASE DE CONHECIMENTO (RESTO DO SEU C√ìDIGO) ---
@app.route('/kb/upload', methods=['POST'])
def kb_upload():
    # ... o resto do seu c√≥digo para kb_upload ...
    # (Copie e cole a partir daqui o que voc√™ j√° tinha no seu app.py)
    try:
        kb = load_kb()
        # ... seu c√≥digo continua aqui ...

        # Exemplo de como voc√™ usaria a busca dentro de uma fun√ß√£o da sua IA:
        # Quando o usu√°rio faz uma pergunta que a IA n√£o sabe responder diretamente,
        # ou que exige informa√ß√£o atualizada, voc√™ chamaria:
        # search_query = "informa√ß√£o sobre " + pergunta_do_usuario
        # search_results = google_search_api(search_query)
        # return jsonify({"response": "Encontrei isto: " + str(search_results)}) # Adaptar a resposta

        
        # Upload de arquivo
        if 'file' in request.files and request.files['file'].filename:
            file = request.files['file']
            ext = os.path.splitext(file.filename)[1].lower()
            file_id = str(uuid.uuid4())
            filename = f"{file_id}{ext}"
            file_path = os.path.join(KB_DIR, filename)
            file.save(file_path)
            
            # Extra√ß√£o de texto
            extracted_text = ''
            if ext == '.pdf' and PyPDF2:
                try:
                    with open(file_path, 'rb') as f:
                        reader = PyPDF2.PdfReader(f)
                        for page in reader.pages:
                            extracted_text += page.extract_text() or ''
                except Exception as e:
                    print(f"Erro ao extrair PDF: {e}")
                    extracted_text = ''
            elif ext in ['.docx'] and docx:
                try:
                    doc = docx.Document(file_path)
                    extracted_text = '\n'.join([p.text for p in doc.paragraphs])
                except Exception as e:
                    print(f"Erro ao extrair DOCX: {e}")
                    extracted_text = ''
            elif ext in ['.txt', '.md', '.csv']:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        extracted_text = f.read()
                except Exception as e:
                    print(f"Erro ao extrair texto: {e}")
                    extracted_text = ''
            
            kb.append({
                'id': file_id,
                'type': 'file',
                'name': file.filename,
                'filename': filename,
                'content': extracted_text[:20000] if extracted_text else ''
            })
        
        # Cadastro de FAQ/manual (texto)
        faq = request.form.get('faq', '').strip()
        if faq:
            faq_id = str(uuid.uuid4())
            kb.append({
                'id': faq_id,
                'type': 'faq',
                'name': faq[:40] + ('...' if len(faq) > 40 else ''),
                'content': faq
            })
        
        save_kb(kb)
        return jsonify({'success': True})
        
    except Exception as e:
        print(f"Erro ao fazer upload para KB: {e}")
        return jsonify({'error': 'Erro ao processar upload'}), 500

@app.route('/kb/list')
def kb_list():
    try:
        kb = load_kb()
        q = request.args.get('q', '').strip().lower()
        if q:
            kb = [item for item in kb if q in item.get('name','').lower() or q in item.get('content','').lower()]
        return jsonify(kb)
    except Exception as e:
        print(f"Erro ao listar KB: {e}")
        return jsonify([])

@app.route('/kb/remove/<item_id>', methods=['DELETE'])
def kb_remove(item_id):
    try:
        kb = load_kb()
        item = next((i for i in kb if i['id'] == item_id), None)
        if not item:
            return jsonify({'error': 'Item n√£o encontrado'}), 404
        
        kb = [i for i in kb if i['id'] != item_id]
        
        if item['type'] == 'file' and 'filename' in item:
            try:
                os.remove(os.path.join(KB_DIR, item['filename']))
            except Exception:
                pass
        
        save_kb(kb)
        return jsonify({'success': True})
        
    except Exception as e:
        print(f"Erro ao remover item da KB: {e}")
        return jsonify({'error': 'Erro ao remover item'}), 500

@app.route('/kb/download/<item_id>')
def kb_download(item_id):
    try:
        kb = load_kb()
        item = next((i for i in kb if i['id'] == item_id and i['type'] == 'file'), None)
        if not item:
            return 'Arquivo n√£o encontrado', 404
        return send_from_directory(KB_DIR, item['filename'], as_attachment=True, download_name=item['name'])
    except Exception as e:
        print(f"Erro ao fazer download: {e}")
        return 'Erro interno', 500

# --- CONSTANTES E CONFIGURA√á√ïES DO CHAT ---
SYSTEM_PROMPT = "Voc√™ √© a A.E.M.I, uma IA especialista em manuten√ß√£o industrial e um projeto do canal 'Manuten√ß√£o Industrial ARQUIVOS'. Seja direta e objetiva. Responda apenas a perguntas relacionadas a este dom√≠nio. Se a pergunta n√£o for sobre manuten√ß√£o industrial, diga que voc√™ s√≥ pode ajudar com t√≥picos relacionados √† manuten√ß√£o industrial."
MAX_HISTORY_LENGTH = 10

# --- FUN√á√ïES DE PESQUISA NA INTERNET ---
def search_internet(query, max_results=5):
    """Pesquisa na internet usando DuckDuckGo e retorna resultados com links."""
    try:
        # Remove caracteres especiais da query
        clean_query = re.sub(r'[^\w\s-]', '', query).strip()
        
        # URL da API do DuckDuckGo
        search_url = f"https://html.duckduckgo.com/html/?q={quote(clean_query)}"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(search_url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            return {"error": "Erro ao conectar com o servi√ßo de pesquisa"}
        
        # Parse do HTML se BeautifulSoup estiver dispon√≠vel
        if BeautifulSoup:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            results = []
            result_divs = soup.find_all('div', class_='result__body')
            
            for i, div in enumerate(result_divs[:max_results]):
                title_elem = div.find('a', class_='result__a')
                snippet_elem = div.find('a', class_='result__snippet')
                
                if title_elem and snippet_elem:
                    title = title_elem.get_text(strip=True)
                    url = title_elem.get('href', '')
                    snippet = snippet_elem.get_text(strip=True)
                    
                    # Limpa URLs malformadas
                    if url.startswith('//'):
                        url = 'https:' + url
                    elif not url.startswith('http'):
                        continue
                    
                    results.append({
                        'title': title,
                        'url': url,
                        'snippet': snippet
                    })
            
            return {"results": results, "query": clean_query}
        else:
            return {"error": "Biblioteca de parsing n√£o dispon√≠vel"}
            
    except Exception as e:
        print(f"Erro na pesquisa: {e}")
        return {"error": f"Erro durante a pesquisa: {str(e)}"}

def extract_page_content(url, max_chars=1000):
    """Extrai conte√∫do de uma p√°gina web para an√°lise."""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        response = requests.get(url, headers=headers, timeout=10, allow_redirects=True)
        
        if response.status_code == 200 and BeautifulSoup:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Remove elementos desnecess√°rios
            for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'iframe', 'noscript']):
                element.decompose()
            
            # Tenta encontrar o conte√∫do principal
            main_content = soup.find('main') or soup.find('article') or soup.find('div', {'class': ['content', 'post', 'article']})
            
            if main_content:
                text = main_content.get_text()
            else:
                text = soup.get_text()
            
            # Limpa o texto
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text = ' '.join(chunk for chunk in chunks if chunk)
            
            # Remove linhas muito curtas e repetitivas
            sentences = text.split('.')
            meaningful_sentences = []
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) > 20 and sentence not in meaningful_sentences:
                    meaningful_sentences.append(sentence)
            
            cleaned_text = '. '.join(meaningful_sentences[:10])  # Primeiras 10 frases
            
            return cleaned_text[:max_chars]
        
        return ""
    except Exception as e:
        print(f"Erro ao extrair conte√∫do de {url}: {e}")
        return ""

def should_search_internet(message):
    """Determina se a mensagem requer pesquisa na internet."""
    search_triggers = [
        'pesquisar', 'buscar', 'procurar', 'pesquise', 'busque', 'procure',
        '√∫ltimas', 'recente', 'atual', 'hoje', 'agora', 'not√≠cias',
        'pre√ßo', 'valor', 'custo', 'onde comprar', 'fornecedor',
        'norma', 'regulamento', 'lei', 'nbr', 'iso', 'abnt',
        'fabricante', 'marca', 'modelo', 'especifica√ß√£o',
        'curso', 'treinamento', 'certifica√ß√£o', 'capacita√ß√£o',
        'empresa', 'f√°brica', 'cat√°logo', 'manual',
        'novidade', 'lan√ßamento', 'tecnologia', 'inova√ß√£o',
        'mercado', 'tend√™ncia', 'estat√≠stica', 'dados',
        'comparar', 'diferen√ßa', 'vantagem', 'desvantagem'
    ]
    
    message_lower = message.lower()
    
    # Busca por gatilhos diretos
    if any(trigger in message_lower for trigger in search_triggers):
        return True
    
    # Busca por padr√µes de perguntas que podem precisar de informa√ß√µes atuais
    current_info_patterns = [
        'qual', 'quais', 'como', 'onde', 'quando', 'por que', 'porque',
        'existe', 'tem', 'h√°', 'possui', 'funciona', 'serve'
    ]
    
    # Se a mensagem cont√©m padr√µes de pergunta E palavras t√©cnicas, pode precisar de pesquisa
    if any(pattern in message_lower for pattern in current_info_patterns):
        technical_words = [
            'equipamento', 'm√°quina', 'motor', 'bomba', 'v√°lvula', 'sensor',
            'automa√ß√£o', 'industrial', 'manuten√ß√£o', 'falha', 'diagn√≥stico',
            'lubrifica√ß√£o', 'rolamento', 'correia', 'engrenagem', 'hidr√°ulica',
            'pneum√°tica', 'el√©trica', 'eletr√¥nica', 'software', 'sistema'
        ]
        
        if any(word in message_lower for word in technical_words):
            return True
    
    return False

def analyze_search_content(search_data, original_query):
    """Analisa o conte√∫do dos resultados de pesquisa e gera uma resposta elaborada."""
    if "error" in search_data:
        return f"üîç **Pesquisa na Internet**\n\n‚ùå {search_data['error']}\n\nComo alternativa, posso ajudar com base no meu conhecimento sobre manuten√ß√£o industrial."
    
    results = search_data.get("results", [])
    if not results:
        return f"üîç **Pesquisa na Internet**\n\nüö´ Nenhum resultado encontrado para: \"{original_query}\"\n\nComo alternativa, posso ajudar com base no meu conhecimento sobre manuten√ß√£o industrial."
    
    # Extrai conte√∫do dos primeiros resultados
    content_sources = []
    for result in results[:3]:  # Analisa os 3 primeiros resultados
        content = extract_page_content(result['url'], max_chars=800)
        if content.strip():
            content_sources.append({
                'title': result['title'],
                'url': result['url'],
                'content': content,
                'snippet': result.get('snippet', '')
            })
    
    if not content_sources:
        return f"üîç **Pesquisa na Internet**\n\n‚ö†Ô∏è Encontrei resultados para \"{original_query}\", mas n√£o consegui acessar o conte√∫do dos sites.\n\nComo alternativa, posso ajudar com base no meu conhecimento sobre manuten√ß√£o industrial."
    
    # Prepara o contexto para o LLM
    context = f"Pergunta do usu√°rio: {original_query}\n\n"
    context += "Informa√ß√µes encontradas na internet:\n\n"
    
    for i, source in enumerate(content_sources, 1):
        context += f"Fonte {i} - {source['title']}:\n"
        context += f"URL: {source['url']}\n"
        context += f"Conte√∫do: {source['content']}\n\n"
    
    # Gera resposta usando LLM
    try:
        client = get_text_client()
        if client:
            prompt = f"""Como A.E.M.I, especialista em manuten√ß√£o industrial, responda √† pergunta do usu√°rio com base nas informa√ß√µes encontradas na internet. Seja detalhada e t√©cnica.

{context}

Instru√ß√µes:
1. Responda de forma completa e t√©cnica sobre o assunto
2. Use as informa√ß√µes das fontes para embasar sua resposta
3. Mantenha o foco em manuten√ß√£o industrial
4. No final, cite as fontes utilizadas
5. Seja pr√°tica e objetiva

Resposta:"""

            response = client.text_generation(
                prompt,
                max_new_tokens=1000,
                temperature=0.7,
                return_full_text=False
            )
            
            ai_response = response.strip()
            
            # Adiciona as fontes ao final
            sources_text = "\n\nüìö **Fontes consultadas:**\n"
            for i, source in enumerate(content_sources, 1):
                sources_text += f"{i}. {source['title']}\n   üîó {source['url']}\n"
            
            return f"üîç **Pesquisa na Internet - \"{original_query}\"**\n\n{ai_response}{sources_text}"
        
    except Exception as e:
        print(f"Erro ao gerar resposta com LLM: {e}")
    
    # Fallback: resposta baseada nos snippets
    response = f"üîç **Pesquisa na Internet - \"{original_query}\"**\n\n"
    response += "üìù **Informa√ß√µes encontradas:**\n\n"
    
    for i, source in enumerate(content_sources, 1):
        response += f"**{i}. {source['title']}**\n"
        if source['snippet']:
            response += f"üìã {source['snippet']}\n"
        response += f"üîó {source['url']}\n\n"
    
    response += "üìö **Fontes consultadas:**\n"
    for i, source in enumerate(content_sources, 1):
        response += f"{i}. {source['title']} - {source['url']}\n"
    
    return response

# --- FUN√á√ïES DE PROCESSAMENTO ---
def get_text_client():
    """Cria e retorna um cliente para o modelo de linguagem."""
    if not HUGGING_FACE_TOKEN or not InferenceClient:
        return None
    return InferenceClient(model="meta-llama/Meta-Llama-3-8B-Instruct", token=HUGGING_FACE_TOKEN)

def get_vision_client():
    """Cria e retorna um cliente para an√°lise de imagens."""
    if not HUGGING_FACE_TOKEN or not InferenceClient:
        return None
    return InferenceClient(model="microsoft/kosmos-2-patch14-224", token=HUGGING_FACE_TOKEN)

def analyze_image(image_path):
    """Analisa uma imagem e retorna uma descri√ß√£o detalhada do conte√∫do visual."""
    try:
        # 1. AN√ÅLISE VISUAL COM IA
        vision_analysis = ""
        try:
            client = get_vision_client()
            if client and HUGGING_FACE_TOKEN:
                # Converte imagem para base64
                with open(image_path, 'rb') as f:
                    image_data = f.read()
                
                # Prepara a imagem para an√°lise
                img = Image.open(io.BytesIO(image_data))
                
                # Redimensiona se muito grande
                if img.width > 1024 or img.height > 1024:
                    img.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
                
                # Converte para RGB se necess√°rio
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # Salva temporariamente
                temp_buffer = io.BytesIO()
                img.save(temp_buffer, format='JPEG', quality=85)
                temp_buffer.seek(0)
                
                # Faz a an√°lise visual com IA
                try:
                    result = client.image_to_text(temp_buffer.getvalue())
                    vision_analysis = result.get('generated_text', '') if isinstance(result, dict) else str(result)
                except Exception as e:
                    print(f"Erro na an√°lise visual: {e}")
                    vision_analysis = ""
        except Exception as e:
            print(f"Erro no cliente de vis√£o: {e}")
            vision_analysis = ""
        
        # 2. AN√ÅLISE T√âCNICA DA IMAGEM
        with open(image_path, 'rb') as f:
            image_data = f.read()
        
        img = Image.open(io.BytesIO(image_data))
        width, height = img.size
        format_img = img.format or "Desconhecido"
        
        # 3. AN√ÅLISE BASEADA EM CARACTER√çSTICAS VISUAIS
        visual_characteristics = analyze_visual_characteristics(img)
        
        # 4. AN√ÅLISE DO NOME DO ARQUIVO
        filename = os.path.basename(image_path).lower()
        context_hints = analyze_filename_context(filename)
        
        # 5. MONTA A RESPOSTA COMPLETA
        if vision_analysis:
            # Se temos an√°lise de IA, usamos ela como base
            description = f"""üîç **An√°lise Visual da Imagem:**

ü§ñ **O que vejo na imagem:**
{vision_analysis}

üîß **An√°lise AEMI (Manuten√ß√£o Industrial):**
{interpret_for_maintenance(vision_analysis)}

üìä **Caracter√≠sticas t√©cnicas:**
- Formato: {format_img} | Dimens√µes: {width}x{height}px
{visual_characteristics}
{context_hints}

üí° **Como posso ajudar:**
Baseado no que vejo, posso te orientar sobre:
‚Ä¢ Identifica√ß√£o de componentes
‚Ä¢ An√°lise de falhas ou desgastes
‚Ä¢ Procedimentos de manuten√ß√£o
‚Ä¢ Normas de seguran√ßa
‚Ä¢ Ferramentas recomendadas

‚ùì **Pr√≥ximo passo:** Me conte qual √© sua d√∫vida espec√≠fica sobre esta imagem."""
        else:
            # Fallback para an√°lise baseada em caracter√≠sticas
            description = f"""üì∏ **An√°lise da Imagem:**

‚ö†Ô∏è **An√°lise Visual Limitada:**
N√£o foi poss√≠vel fazer an√°lise visual completa com IA no momento.

üîß **An√°lise AEMI baseada em caracter√≠sticas:**
{visual_characteristics}
{context_hints}

üìä **Informa√ß√µes t√©cnicas:**
- Formato: {format_img}
- Dimens√µes: {width}x{height} pixels

üí° **Como posso ajudar:**
Mesmo sem an√°lise visual completa, posso te orientar sobre manuten√ß√£o industrial se voc√™ me descrever:
‚Ä¢ Que equipamento/componente est√° na imagem
‚Ä¢ Qual problema voc√™ est√° enfrentando
‚Ä¢ Que tipo de an√°lise precisa

‚ùì **Me conte:** O que voc√™ v√™ na imagem e como posso te ajudar?"""
        
        return description
        
    except Exception as e:
        return f"‚ùå Erro ao analisar imagem: {str(e)}\n\nTente enviar novamente ou descreva o que voc√™ v√™ na imagem para que eu possa te ajudar."

def analyze_visual_characteristics(img):
    """Analisa caracter√≠sticas visuais b√°sicas da imagem."""
    try:
        # An√°lise de cores
        colors = img.getcolors(maxcolors=256*256*256)
        if colors:
            dominant_colors = sorted(colors, key=lambda x: x[0], reverse=True)[:3]
            
            # Interpreta√ß√£o das cores para contexto industrial
            color_hints = []
            for count, color in dominant_colors:
                if isinstance(color, tuple) and len(color) >= 3:
                    r, g, b = color[:3]
                    if r > 200 and g < 100 and b < 100:  # Vermelho
                        color_hints.append("Poss√≠vel indica√ß√£o de perigo/parada")
                    elif r > 200 and g > 200 and b < 100:  # Amarelo
                        color_hints.append("Poss√≠vel sinaliza√ß√£o de aten√ß√£o")
                    elif r < 100 and g > 150 and b < 100:  # Verde
                        color_hints.append("Poss√≠vel indica√ß√£o de funcionamento normal")
                    elif r < 100 and g < 100 and b > 150:  # Azul
                        color_hints.append("Poss√≠vel componente hidr√°ulico")
            
            if color_hints:
                return f"\nüé® **Indica√ß√µes visuais:** {', '.join(color_hints)}"
        
        return "\nüé® **An√°lise de cores:** Variadas (equipamento/ambiente industrial)"
    except:
        return ""

def analyze_filename_context(filename):
    """Analisa o nome do arquivo para contexto."""
    maintenance_keywords = {
        'motor': 'Motor el√©trico/mec√¢nico',
        'rolamento': 'Rolamento/bearing',
        'bearing': 'Rolamento',
        'engrenagem': 'Sistema de engrenagens',
        'gear': 'Engrenagem',
        'bomba': 'Bomba hidr√°ulica/pneum√°tica',
        'pump': 'Bomba',
        'valvula': 'V√°lvula',
        'valve': 'V√°lvula',
        'correia': 'Correia/belt',
        'belt': 'Correia',
        'polia': 'Polia',
        'pulley': 'Polia',
        'falha': 'An√°lise de falha',
        'failure': 'Falha',
        'desgaste': 'Desgaste',
        'wear': 'Desgaste',
        'manutencao': 'Manuten√ß√£o',
        'maintenance': 'Manuten√ß√£o',
        'hidraulica': 'Sistema hidr√°ulico',
        'hydraulic': 'Hidr√°ulico',
        'pneumatic': 'Pneum√°tico',
        'pneumatica': 'Pneum√°tico'
    }
    
    found = []
    for keyword, description in maintenance_keywords.items():
        if keyword in filename:
            found.append(description)
    
    if found:
        return f"\nüè∑Ô∏è **Contexto do arquivo:** {', '.join(found)}"
    return ""

def interpret_for_maintenance(vision_text):
    """Interpreta a an√°lise visual no contexto de manuten√ß√£o industrial."""
    vision_lower = vision_text.lower()
    
    interpretations = []
    
    # Identifica equipamentos
    if any(word in vision_lower for word in ['motor', 'engine', 'm√°quina', 'machine']):
        interpretations.append("üîß **Motor/M√°quina identificado** - Posso ajudar com an√°lise de vibra√ß√£o, alinhamento, lubrifica√ß√£o")
    
    if any(word in vision_lower for word in ['rolamento', 'bearing', 'roda', 'wheel']):
        interpretations.append("‚öôÔ∏è **Rolamento detectado** - Posso orientar sobre montagem, desmontagem e an√°lise de falhas")
    
    if any(word in vision_lower for word in ['tubo', 'pipe', 'mangueira', 'hose']):
        interpretations.append("üîß **Sistema hidr√°ulico/pneum√°tico** - Posso ajudar com press√µes, veda√ß√µes e conex√µes")
    
    if any(word in vision_lower for word in ['parafuso', 'bolt', 'rosca', 'thread']):
        interpretations.append("üî© **Fixa√ß√£o detectada** - Posso orientar sobre torques e procedimentos de aperto")
    
    if any(word in vision_lower for word in ['√≥leo', 'oil', 'graxa', 'grease', 'lubrificante']):
        interpretations.append("üõ¢Ô∏è **Lubrifica√ß√£o identificada** - Posso ajudar com intervalos e tipos de lubrificantes")
    
    # Identifica problemas
    if any(word in vision_lower for word in ['rachadura', 'crack', 'quebrado', 'broken']):
        interpretations.append("‚ö†Ô∏è **Poss√≠vel falha estrutural** - Recomendo inspe√ß√£o detalhada e avalia√ß√£o de seguran√ßa")
    
    if any(word in vision_lower for word in ['oxida√ß√£o', 'rust', 'corros√£o', 'corrosion']):
        interpretations.append("üî¥ **Corros√£o detectada** - Posso orientar sobre tratamento e preven√ß√£o")
    
    if any(word in vision_lower for word in ['desgaste', 'wear', 'gasto', 'worn']):
        interpretations.append("üìâ **Desgaste identificado** - Posso ajudar a avaliar vida √∫til restante")
    
    if interpretations:
        return '\n'.join(interpretations)
    else:
        return "üìã **An√°lise geral:** Identifiquei elementos industriais. Me descreva sua d√∫vida espec√≠fica para orienta√ß√£o detalhada."

def generate_chat_response(chat_history):
    """Processa um hist√≥rico de chat e retorna a resposta do modelo."""
    client = get_text_client()
    if not client:
        return "Desculpe, o servi√ßo de IA n√£o est√° dispon√≠vel no momento."
    
    try:
        response_generator = client.chat_completion(
            messages=chat_history,
            max_tokens=1500,
            stream=False
        )
        return response_generator.choices[0].message.content
    except Exception as e:
        print(f"Erro na gera√ß√£o de resposta: {e}")
        return "Desculpe, ocorreu um erro ao gerar a resposta."

# --- ROTAS PRINCIPAIS ---
@app.route('/')
def index():
    status = {
        "status": "online",
        "message": "Servidor da AEMI (vers√£o com Llama 3 8B e mem√≥ria) est√° no ar.",
        "services": {
            "huggingface": "‚úÖ Configurado" if HUGGING_FACE_TOKEN else "‚ùå N√£o configurado",
            "google_search": "‚úÖ Configurado" if (GOOGLE_API_KEY and GOOGLE_CSE_ID) else "‚ùå N√£o configurado"
        }
    }
    return jsonify(status)

@app.route('/health')
def health():
    return jsonify({
        "status": "healthy",
        "timestamp": str(__import__('datetime').datetime.now()),
        "google_api": bool(GOOGLE_API_KEY and GOOGLE_CSE_ID),
        "hf_token": bool(HUGGING_FACE_TOKEN)
    })

@app.route('/chat', methods=['POST'])
def chat():
    try:
        user_message = request.form.get('message', '')
        if not user_message.strip():
            return jsonify({"error": "Nenhuma mensagem enviada."}), 400

        # 1. Buscar resposta na base de conhecimento
        kb = load_kb()
        user_message_lower = user_message.lower()
        import difflib
        
        # Busca exata ou substring em FAQ
        for item in kb:
            if item['type'] == 'faq' and user_message_lower in item.get('content','').lower():
                return jsonify({'response': f"[Base de Conhecimento]\n{item['content'][:600]}"})
        
        # Busca fuzzy em FAQ
        best_match = None
        best_ratio = 0.0
        for item in kb:
            if item['type'] == 'faq':
                content = item.get('content','').lower()
                ratio = difflib.SequenceMatcher(None, user_message_lower, content).ratio()
                if ratio > best_ratio:
                    best_ratio = ratio
                    best_match = item
        
        if best_match and best_ratio > 0.45:
            return jsonify({'response': f"[Base de Conhecimento - resposta aproximada]\n{best_match['content'][:600]}"})

        # 2. Buscar por conte√∫do extra√≠do de arquivos
        for item in kb:
            if item['type'] == 'file' and item.get('content') and user_message_lower in item['content'].lower():
                return jsonify({'response': f"[Arquivo: {item['name']}]\n{item['content'][:600]}..."})
        
        # Busca fuzzy no conte√∫do de arquivos
        best_file_match = None
        best_file_ratio = 0.0
        for item in kb:
            if item['type'] == 'file' and item.get('content'):
                content = item['content'].lower()
                ratio = difflib.SequenceMatcher(None, user_message_lower, content).ratio()
                if ratio > best_file_ratio:
                    best_file_ratio = ratio
                    best_file_match = item
        
        if best_file_match and best_file_ratio > 0.45:
            return jsonify({'response': f"[Arquivo (aprox.): {best_file_match['name']}]\n{best_file_match['content'][:600]}..."})

        # 3. Buscar por nome de arquivo/documento
        for item in kb:
            if item['type'] == 'file' and user_message_lower in item.get('name','').lower():
                return jsonify({'response': f"Encontrei um documento relacionado: {item['name']}\nClique para baixar: /kb/download/{item['id']}"})
        
        # Fuzzy para nome de arquivo
        best_file = None
        best_file_ratio = 0.0
        for item in kb:
            if item['type'] == 'file':
                name = item.get('name','').lower()
                ratio = difflib.SequenceMatcher(None, user_message_lower, name).ratio()
                if ratio > best_file_ratio:
                    best_file_ratio = ratio
                    best_file = item
        
        if best_file and best_file_ratio > 0.45:
            return jsonify({'response': f"Encontrei um documento relacionado: {best_file['name']}\nClique para baixar: /kb/download/{best_file['id']}"})

        # 4. Verificar se precisa de pesquisa na internet
        if should_search_internet(user_message):
            print(f"Realizando pesquisa na internet para: {user_message}")
            search_results = search_internet(user_message, max_results=5)
            analyzed_results = analyze_search_content(search_results, user_message)
            
            # Se encontrou e analisou resultados, retorna eles
            if "results" in search_results and search_results["results"]:
                return jsonify({"response": analyzed_results})
            
            # Se n√£o encontrou, continua para o LLM com uma nota sobre a pesquisa
            user_message += " (Pesquisa na internet n√£o retornou resultados √∫teis)"
        
        # 5. Se n√£o encontrou na KB nem precisou pesquisar, usar o LLM
        if 'chat_history' not in session:
            session['chat_history'] = [{"role": "system", "content": SYSTEM_PROMPT}]
        
        # Verifica se h√° conte√∫do de arquivo enviado para incluir na an√°lise
        enhanced_message = user_message
        if 'uploaded_file_content' in session and session['uploaded_file_content']:
            file_data = session['uploaded_file_content']
            
            # Cria contexto baseado no tipo de an√°lise
            if file_data.get('analysis_type') == 'visual':
                enhanced_message = f"""Como A.E.M.I, especialista em manuten√ß√£o industrial, analise esta imagem e responda: {user_message}

üì∏ **Arquivo de Imagem:** {file_data['filename']}
üîç **An√°lise Visual Completa:**
{file_data['content']}

**Instru√ß√µes:**
- Responda com base na an√°lise visual da imagem
- Foque em aspectos de manuten√ß√£o industrial
- Seja t√©cnica e detalhada
- Se identificar problemas, sugira solu√ß√µes"""
            
            elif file_data.get('analysis_type') == 'text':
                enhanced_message = f"""Como A.E.M.I, especialista em manuten√ß√£o industrial, analise este documento e responda: {user_message}

üìÑ **Documento:** {file_data['filename']} (tipo: {file_data['type']})

**Conte√∫do do Documento:**
{file_data['content']}

**Instru√ß√µes:**
- Analise o conte√∫do do documento em detalhes
- Responda √† pergunta com base nas informa√ß√µes do arquivo
- Seja espec√≠fica e t√©cnica
- Cite trechos relevantes do documento quando apropriado"""
            
            else:
                enhanced_message = f"""Pergunta sobre o arquivo enviado: {user_message}

Arquivo: {file_data['filename']} (tipo: {file_data['type']})

Conte√∫do do arquivo:
{file_data['content']}

Instru√ß√µes: Analise o conte√∫do do arquivo e responda √† pergunta do usu√°rio com base nessas informa√ß√µes."""
        
        session['chat_history'].append({"role": "user", "content": enhanced_message})
        
        if len(session['chat_history']) > MAX_HISTORY_LENGTH:
            session['chat_history'] = [session['chat_history'][0]] + session['chat_history'][-MAX_HISTORY_LENGTH:]
        
        print(f"Processando com hist√≥rico de {len(session['chat_history'])} mensagens...")
        bot_response = generate_chat_response(session['chat_history'])
        
        session['chat_history'].append({"role": "assistant", "content": bot_response})
        session.modified = True
        
        print("Resposta da IA gerada e hist√≥rico atualizado.")
        return jsonify({"response": bot_response})

    except Exception as e:
        print(f"ERRO GERAL na rota /chat: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": f"Ocorreu um erro inesperado no servidor. Detalhes: {str(e)}"}), 500

@app.route('/upload-file', methods=['POST'])
def upload_file():
    """Upload de arquivo para an√°lise no chat."""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'Nenhum arquivo enviado'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'Nenhum arquivo selecionado'}), 400
        
        # Salva o arquivo temporariamente
        file_id = str(uuid.uuid4())
        ext = os.path.splitext(file.filename)[1].lower()
        filename = f"{file_id}{ext}"
        temp_path = os.path.join(KB_DIR, filename)
        file.save(temp_path)
        
        # Analisa o arquivo baseado no tipo
        response_text = ""
        file_content = ""
        
        # Verifica se √© imagem
        if ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']:
            response_text = "üì∏ **ARQUIVO RECEBIDO, NO QUE POSSO AJUDAR?**"
            
            # An√°lise visual da imagem
            try:
                visual_analysis = analyze_image(temp_path)
                if visual_analysis:
                    # Salva an√°lise na sess√£o
                    session['uploaded_file_content'] = {
                        'filename': file.filename,
                        'type': 'image',
                        'content': visual_analysis,
                        'analysis_type': 'visual'
                    }
                    session.modified = True
            except Exception as e:
                print(f"Erro na an√°lise visual: {e}")
        
        # Verifica se √© PDF
        elif ext == '.pdf' and PyPDF2:
            response_text = "üìÑ **ARQUIVO RECEBIDO, NO QUE POSSO AJUDAR?**"
            
            try:
                with open(temp_path, 'rb') as f:
                    reader = PyPDF2.PdfReader(f)
                    text_content = ""
                    
                    # Extrai texto de at√© 15 p√°ginas
                    pages_to_read = min(15, len(reader.pages))
                    for i in range(pages_to_read):
                        try:
                            page_text = reader.pages[i].extract_text() or ''
                            text_content += f"\n--- P√°gina {i+1} ---\n{page_text}"
                        except:
                            continue
                    
                    # Salva na sess√£o
                    session['uploaded_file_content'] = {
                        'filename': file.filename,
                        'type': 'pdf',
                        'content': text_content[:15000],  # Aumenta limite
                        'analysis_type': 'text'
                    }
                    session.modified = True
            except Exception as e:
                print(f"Erro ao processar PDF: {e}")
        
        # Verifica se √© documento Word
        elif ext in ['.docx'] and docx:
            response_text = "üìÑ **ARQUIVO RECEBIDO, NO QUE POSSO AJUDAR?**"
            
            try:
                doc = docx.Document(temp_path)
                paragraphs = []
                
                # Extrai par√°grafos com formata√ß√£o
                for i, para in enumerate(doc.paragraphs):
                    if para.text.strip():
                        paragraphs.append(f"Par√°grafo {i+1}: {para.text.strip()}")
                
                text_content = '\n'.join(paragraphs[:30])  # Primeiros 30 par√°grafos
                
                # Salva na sess√£o
                session['uploaded_file_content'] = {
                    'filename': file.filename,
                    'type': 'docx',
                    'content': text_content[:15000],  # Aumenta limite
                    'analysis_type': 'text'
                }
                session.modified = True
            except Exception as e:
                print(f"Erro ao processar documento: {e}")
        
        # Arquivo de texto
        elif ext in ['.txt', '.md', '.csv']:
            response_text = "üìù **ARQUIVO RECEBIDO, NO QUE POSSO AJUDAR?**"
            
            try:
                with open(temp_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read(15000)  # Aumenta limite
                    
                    # Salva na sess√£o
                    session['uploaded_file_content'] = {
                        'filename': file.filename,
                        'type': ext,
                        'content': content,
                        'analysis_type': 'text'
                    }
                    session.modified = True
            except Exception as e:
                print(f"Erro ao processar arquivo: {e}")
        
        else:
            response_text = "üìé **ARQUIVO RECEBIDO, NO QUE POSSO AJUDAR?**"
        
        # Remove o arquivo tempor√°rio
        try:
            os.remove(temp_path)
        except:
            pass
        
        return jsonify({
            'response': response_text,
            'filename': file.filename,
            'file_type': ext
        })
    
    except Exception as e:
        print(f"Erro no upload de arquivo: {e}")
        return jsonify({'error': 'Erro ao processar arquivo'}), 500

@app.route('/search-internet', methods=['POST'])
def search_internet_route():
    """Rota para pesquisa manual na internet."""
    try:
        query = request.form.get('query', '').strip()
        if not query:
            return jsonify({"error": "Query de pesquisa n√£o fornecida"}), 400
        
        max_results = int(request.form.get('max_results', 5))
        search_results = search_internet(query, max_results)
        
        return jsonify(search_results)
    
    except Exception as e:
        print(f"Erro na pesquisa manual: {e}")
        return jsonify({"error": "Erro ao realizar pesquisa"}), 500

@app.route('/extract-content', methods=['POST'])
def extract_content_route():
    """Rota para extrair conte√∫do de uma URL."""
    try:
        url = request.form.get('url', '').strip()
        if not url:
            return jsonify({"error": "URL n√£o fornecida"}), 400
        
        max_chars = int(request.form.get('max_chars', 1000))
        content = extract_page_content(url, max_chars)
        
        return jsonify({"content": content, "url": url})
    
    except Exception as e:
        print(f"Erro na extra√ß√£o de conte√∫do: {e}")
        return jsonify({"error": "Erro ao extrair conte√∫do"}), 500

@app.route('/clear-session', methods=['POST'])
def clear_session():
    """Limpa o hist√≥rico de chat da sess√£o do usu√°rio."""
    try:
        if 'chat_history' in session:
            session.pop('chat_history', None)
            print("Sess√£o do usu√°rio limpa.")
        return jsonify({"status": "success", "message": "Hist√≥rico de chat limpo."})
    except Exception as e:
        print(f"Erro ao limpar sess√£o: {e}")
        return jsonify({"error": "Erro ao limpar sess√£o"}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=True)
