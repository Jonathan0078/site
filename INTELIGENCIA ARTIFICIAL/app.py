
import os
import uuid
import json
import mimetypes
import base64
import requests
import re
from urllib.parse import quote, urljoin
from PIL import Image
import io
try:
    import PyPDF2
except ImportError:
    PyPDF2 = None
try:
    import docx
except ImportError:
    docx = None
try:
    from bs4 import BeautifulSoup
except ImportError:
    BeautifulSoup = None
from flask import Flask, request, jsonify, send_from_directory, session
from flask_cors import CORS
try:
    from huggingface_hub import InferenceClient
except ImportError:
    InferenceClient = None

# --- INICIALIZA√á√ÉO DO FLASK ---
app = Flask(__name__)

# Permite apenas o dom√≠nio do GitHub Pages do seu projeto e o endere√ßo do backend Render
CORS(app, supports_credentials=True, origins=[
    "https://jonathan0078.github.io",
    "https://aemi.onrender.com"
])

# Carrega as chaves da aplica√ß√£o a partir de vari√°veis de ambiente
FLASK_SECRET_KEY = os.getenv("FLASK_SECRET_KEY", "dev-key-change-in-production")
HUGGING_FACE_TOKEN = os.getenv("HF_TOKEN")

# Valida√ß√£o das chaves
if not HUGGING_FACE_TOKEN:
    print("AVISO: Token da Hugging Face n√£o configurado. Chat com IA n√£o funcionar√°.")

app.secret_key = FLASK_SECRET_KEY

# --- CONFIGURA√á√ïES DA BASE DE CONHECIMENTO ---
KB_DIR = os.path.join(os.path.dirname(__file__), 'knowledge_base')
KB_DB = os.path.join(KB_DIR, 'kb_data.json')
os.makedirs(KB_DIR, exist_ok=True)

def load_kb():
    if not os.path.exists(KB_DB):
        return []
    try:
        with open(KB_DB, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"Erro ao carregar KB: {e}")
        return []

def save_kb(data):
    try:
        with open(KB_DB, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Erro ao salvar KB: {e}")

# --- ROTAS DA BASE DE CONHECIMENTO ---
@app.route('/kb/upload', methods=['POST'])
def kb_upload():
    try:
        kb = load_kb()
        
        # Upload de arquivo
        if 'file' in request.files and request.files['file'].filename:
            file = request.files['file']
            ext = os.path.splitext(file.filename)[1].lower()
            file_id = str(uuid.uuid4())
            filename = f"{file_id}{ext}"
            file_path = os.path.join(KB_DIR, filename)
            file.save(file_path)
            
            # Extra√ß√£o de texto
            extracted_text = ''
            if ext == '.pdf' and PyPDF2:
                try:
                    with open(file_path, 'rb') as f:
                        reader = PyPDF2.PdfReader(f)
                        for page in reader.pages:
                            extracted_text += page.extract_text() or ''
                except Exception as e:
                    print(f"Erro ao extrair PDF: {e}")
                    extracted_text = ''
            elif ext in ['.docx'] and docx:
                try:
                    doc = docx.Document(file_path)
                    extracted_text = '\n'.join([p.text for p in doc.paragraphs])
                except Exception as e:
                    print(f"Erro ao extrair DOCX: {e}")
                    extracted_text = ''
            elif ext in ['.txt', '.md', '.csv']:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        extracted_text = f.read()
                except Exception as e:
                    print(f"Erro ao extrair texto: {e}")
                    extracted_text = ''
            
            kb.append({
                'id': file_id,
                'type': 'file',
                'name': file.filename,
                'filename': filename,
                'content': extracted_text[:20000] if extracted_text else ''
            })
        
        # Cadastro de FAQ/manual (texto)
        faq = request.form.get('faq', '').strip()
        if faq:
            faq_id = str(uuid.uuid4())
            kb.append({
                'id': faq_id,
                'type': 'faq',
                'name': faq[:40] + ('...' if len(faq) > 40 else ''),
                'content': faq
            })
        
        save_kb(kb)
        return jsonify({'success': True})
        
    except Exception as e:
        print(f"Erro ao fazer upload para KB: {e}")
        return jsonify({'error': 'Erro ao processar upload'}), 500

@app.route('/kb/list')
def kb_list():
    try:
        kb = load_kb()
        q = request.args.get('q', '').strip().lower()
        if q:
            kb = [item for item in kb if q in item.get('name','').lower() or q in item.get('content','').lower()]
        return jsonify(kb)
    except Exception as e:
        print(f"Erro ao listar KB: {e}")
        return jsonify([])

@app.route('/kb/remove/<item_id>', methods=['DELETE'])
def kb_remove(item_id):
    try:
        kb = load_kb()
        item = next((i for i in kb if i['id'] == item_id), None)
        if not item:
            return jsonify({'error': 'Item n√£o encontrado'}), 404
        
        kb = [i for i in kb if i['id'] != item_id]
        
        if item['type'] == 'file' and 'filename' in item:
            try:
                os.remove(os.path.join(KB_DIR, item['filename']))
            except Exception:
                pass
        
        save_kb(kb)
        return jsonify({'success': True})
        
    except Exception as e:
        print(f"Erro ao remover item da KB: {e}")
        return jsonify({'error': 'Erro ao remover item'}), 500

@app.route('/kb/download/<item_id>')
def kb_download(item_id):
    try:
        kb = load_kb()
        item = next((i for i in kb if i['id'] == item_id and i['type'] == 'file'), None)
        if not item:
            return 'Arquivo n√£o encontrado', 404
        return send_from_directory(KB_DIR, item['filename'], as_attachment=True, download_name=item['name'])
    except Exception as e:
        print(f"Erro ao fazer download: {e}")
        return 'Erro interno', 500

# --- CONSTANTES E CONFIGURA√á√ïES DO CHAT ---
SYSTEM_PROMPT = "Voc√™ √© a A.E.M.I, uma IA especialista em manuten√ß√£o industrial e um projeto do canal 'Manuten√ß√£o Industrial ARQUIVOS'. Seja direta e objetiva. Responda apenas a perguntas relacionadas a este dom√≠nio. Se a pergunta n√£o for sobre manuten√ß√£o industrial, diga que voc√™ s√≥ pode ajudar com t√≥picos relacionados √† manuten√ß√£o industrial."
MAX_HISTORY_LENGTH = 10

# --- FUN√á√ïES DE PESQUISA NA INTERNET ---
def search_internet(query, max_results=5):
    """Pesquisa na internet usando DuckDuckGo e retorna resultados com links."""
    try:
        # Remove caracteres especiais da query
        clean_query = re.sub(r'[^\w\s-]', '', query).strip()
        
        # URL da API do DuckDuckGo
        search_url = f"https://html.duckduckgo.com/html/?q={quote(clean_query)}"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(search_url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            return {"error": "Erro ao conectar com o servi√ßo de pesquisa"}
        
        # Parse do HTML se BeautifulSoup estiver dispon√≠vel
        if BeautifulSoup:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            results = []
            result_divs = soup.find_all('div', class_='result__body')
            
            for i, div in enumerate(result_divs[:max_results]):
                title_elem = div.find('a', class_='result__a')
                snippet_elem = div.find('a', class_='result__snippet')
                
                if title_elem and snippet_elem:
                    title = title_elem.get_text(strip=True)
                    url = title_elem.get('href', '')
                    snippet = snippet_elem.get_text(strip=True)
                    
                    # Limpa URLs malformadas
                    if url.startswith('//'):
                        url = 'https:' + url
                    elif not url.startswith('http'):
                        continue
                    
                    results.append({
                        'title': title,
                        'url': url,
                        'snippet': snippet
                    })
            
            return {"results": results, "query": clean_query}
        else:
            return {"error": "Biblioteca de parsing n√£o dispon√≠vel"}
            
    except Exception as e:
        print(f"Erro na pesquisa: {e}")
        return {"error": f"Erro durante a pesquisa: {str(e)}"}

def extract_page_content(url, max_chars=2000):
    """Extrai conte√∫do aprimorado de uma p√°gina web para an√°lise profunda."""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        }
        
        print(f"üåê Acessando: {url}")
        response = requests.get(url, headers=headers, timeout=15, allow_redirects=True)
        
        if response.status_code == 200 and BeautifulSoup:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Remove elementos desnecess√°rios de forma mais abrangente
            for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 
                               'iframe', 'noscript', 'form', 'button', 'input', 
                               'select', 'textarea', 'label', 'fieldset']):
                element.decompose()
            
            # Remove divs com classes comuns de navega√ß√£o e ads
            unwanted_classes = ['nav', 'menu', 'sidebar', 'footer', 'header', 'ad', 
                              'advertisement', 'banner', 'social', 'share', 'comment',
                              'related', 'recommendation', 'popup', 'modal']
            
            for class_name in unwanted_classes:
                for element in soup.find_all(attrs={'class': lambda x: x and any(cls in str(x).lower() for cls in [class_name])}):
                    element.decompose()
            
            # Estrat√©gia melhorada para encontrar conte√∫do principal
            content_selectors = [
                'article', 'main', '[role="main"]',
                '.content', '.post', '.article', '.entry',
                '.main-content', '.post-content', '.article-content',
                '.description', '.summary', '.abstract',
                'div[id*="content"]', 'div[class*="content"]',
                'section', '.section'
            ]
            
            main_content = None
            for selector in content_selectors:
                try:
                    found = soup.select_one(selector)
                    if found and len(found.get_text().strip()) > 200:
                        main_content = found
                        break
                except:
                    continue
            
            # Se n√£o encontrou conte√∫do principal, usa o body mas filtra melhor
            if not main_content:
                main_content = soup.find('body') or soup
            
            # Extrai o texto de forma mais inteligente
            text_parts = []
            
            # Prioriza par√°grafos, t√≠tulos e listas
            for element in main_content.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'li', 'td']):
                text = element.get_text().strip()
                if len(text) > 10 and text not in text_parts:  # Evita duplicatas
                    text_parts.append(text)
            
            # Se n√£o encontrou texto suficiente, pega todo o texto
            if len(' '.join(text_parts)) < 300:
                text_parts = [main_content.get_text()]
            
            # Junta e limpa o texto
            full_text = ' '.join(text_parts)
            
            # Limpeza avan√ßada do texto
            lines = (line.strip() for line in full_text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text = ' '.join(chunk for chunk in chunks if chunk and len(chunk) > 3)
            
            # Remove caracteres especiais em excesso
            import re
            text = re.sub(r'\s+', ' ', text)  # M√∫ltiplos espa√ßos
            text = re.sub(r'[^\w\s\.\,\;\:\!\?\-\(\)\[\]\"\'\/]', '', text)  # Caracteres especiais
            
            # Filtra senten√ßas por qualidade
            sentences = text.split('.')
            quality_sentences = []
            
            for sentence in sentences:
                sentence = sentence.strip()
                # Filtros de qualidade
                if (len(sentence) > 15 and 
                    len(sentence) < 500 and 
                    sentence.count(' ') > 3 and  # Pelo menos 4 palavras
                    not sentence.lower().startswith(('clique', 'click', 'more', 'read', 'ver mais', 'saiba mais')) and
                    sentence not in quality_sentences):
                    quality_sentences.append(sentence)
            
            # Reconstr√≥i o texto limpo
            cleaned_text = '. '.join(quality_sentences[:20])  # Primeiras 20 senten√ßas de qualidade
            
            if len(cleaned_text) < 100:
                # Fallback: pega texto bruto se a limpeza foi muito agressiva
                cleaned_text = text[:max_chars]
            
            result = cleaned_text[:max_chars]
            print(f"‚úÖ Extra√≠do {len(result)} caracteres de conte√∫do √∫til")
            
            return result
        
        print(f"‚ùå Erro HTTP {response.status_code} ao acessar {url}")
        return ""
        
    except requests.exceptions.Timeout:
        print(f"‚è∞ Timeout ao acessar {url}")
        return ""
    except requests.exceptions.RequestException as e:
        print(f"üåê Erro de conex√£o ao acessar {url}: {e}")
        return ""
    except Exception as e:
        print(f"‚ùå Erro geral ao extrair conte√∫do de {url}: {e}")
        return ""

def should_search_internet(message):
    """Determina se a mensagem requer pesquisa na internet."""
    search_triggers = [
        'pesquisar', 'buscar', 'procurar', 'pesquise', 'busque', 'procure',
        '√∫ltimas', 'recente', 'atual', 'hoje', 'agora', 'not√≠cias',
        'pre√ßo', 'valor', 'custo', 'onde comprar', 'fornecedor',
        'norma', 'regulamento', 'lei', 'nbr', 'iso', 'abnt',
        'fabricante', 'marca', 'modelo', 'especifica√ß√£o',
        'curso', 'treinamento', 'certifica√ß√£o', 'capacita√ß√£o',
        'empresa', 'f√°brica', 'cat√°logo', 'manual',
        'novidade', 'lan√ßamento', 'tecnologia', 'inova√ß√£o',
        'mercado', 'tend√™ncia', 'estat√≠stica', 'dados',
        'comparar', 'diferen√ßa', 'vantagem', 'desvantagem'
    ]
    
    message_lower = message.lower()
    
    # Busca por gatilhos diretos
    if any(trigger in message_lower for trigger in search_triggers):
        return True
    
    # Busca por padr√µes de perguntas que podem precisar de informa√ß√µes atuais
    current_info_patterns = [
        'qual', 'quais', 'como', 'onde', 'quando', 'por que', 'porque',
        'existe', 'tem', 'h√°', 'possui', 'funciona', 'serve'
    ]
    
    # Se a mensagem cont√©m padr√µes de pergunta E palavras t√©cnicas, pode precisar de pesquisa
    if any(pattern in message_lower for pattern in current_info_patterns):
        technical_words = [
            'equipamento', 'm√°quina', 'motor', 'bomba', 'v√°lvula', 'sensor',
            'automa√ß√£o', 'industrial', 'manuten√ß√£o', 'falha', 'diagn√≥stico',
            'lubrifica√ß√£o', 'rolamento', 'correia', 'engrenagem', 'hidr√°ulica',
            'pneum√°tica', 'el√©trica', 'eletr√¥nica', 'software', 'sistema'
        ]
        
        if any(word in message_lower for word in technical_words):
            return True
    
    return False

def analyze_search_content(search_data, original_query):
    """Analisa profundamente o conte√∫do dos resultados de pesquisa e gera uma resposta elaborada."""
    if "error" in search_data:
        return f"üîç **Pesquisa na Internet**\n\n‚ùå {search_data['error']}\n\nComo alternativa, posso ajudar com base no meu conhecimento sobre manuten√ß√£o industrial."
    
    results = search_data.get("results", [])
    if not results:
        return f"üîç **Pesquisa na Internet**\n\nüö´ Nenhum resultado encontrado para: \"{original_query}\"\n\nComo alternativa, posso ajudar com base no meu conhecimento sobre manuten√ß√£o industrial."
    
    # Extrai e analisa conte√∫do dos primeiros resultados com mais profundidade
    content_sources = []
    total_content = ""
    
    print(f"üîç Analisando {len(results[:5])} resultados para: {original_query}")
    
    for i, result in enumerate(results[:5], 1):  # Analisa os 5 primeiros resultados
        print(f"üìñ Extraindo conte√∫do do site {i}/5: {result['title']}")
        content = extract_page_content(result['url'], max_chars=2000)  # Aumenta limite para mais conte√∫do
        
        if content.strip() and len(content) > 100:  # S√≥ considera conte√∫do substancial
            content_sources.append({
                'title': result['title'],
                'url': result['url'],
                'content': content,
                'snippet': result.get('snippet', '')
            })
            total_content += f"\n=== {result['title']} ===\n{content}\n"
    
    if not content_sources:
        return f"üîç **Pesquisa na Internet**\n\n‚ö†Ô∏è Encontrei {len(results)} resultados para \"{original_query}\", mas n√£o consegui extrair conte√∫do √∫til dos sites.\n\nüí° **Isso pode acontecer quando:**\n‚Ä¢ Os sites t√™m prote√ß√£o anti-bot\n‚Ä¢ O conte√∫do √© carregado por JavaScript\n‚Ä¢ Sites requerem login\n\nComo alternativa, posso ajudar com base no meu conhecimento sobre manuten√ß√£o industrial."
    
    print(f"‚úÖ Conte√∫do extra√≠do de {len(content_sources)} fontes. Gerando an√°lise...")
    
    # Gera resposta inteligente usando LLM com todo o conte√∫do extra√≠do
    try:
        client = get_text_client()
        if client:
            # Cria um prompt mais elaborado para an√°lise profunda
            prompt = f"""Como A.E.M.I, assistente especialista em manuten√ß√£o industrial, analise profundamente o conte√∫do extra√≠do da internet e forne√ßa uma resposta completa e t√©cnica para a pergunta do usu√°rio.

**PERGUNTA DO USU√ÅRIO:** {original_query}

**CONTE√öDO EXTRA√çDO DA INTERNET:**
{total_content[:12000]}  # Limita para n√£o sobrecarregar

**INSTRU√á√ïES PARA RESPOSTA:**
1. **An√°lise T√©cnica Completa:** Forne√ßa uma resposta detalhada e t√©cnica baseada no conte√∫do real extra√≠do
2. **S√≠ntese Inteligente:** Combine informa√ß√µes de m√∫ltiplas fontes para criar uma resposta coerente
3. **Foco em Manuten√ß√£o Industrial:** Relacione tudo com pr√°ticas de manuten√ß√£o, equipamentos e procedimentos
4. **Informa√ß√µes Pr√°ticas:** Inclua dados espec√≠ficos, especifica√ß√µes, procedimentos ou recomenda√ß√µes encontradas
5. **Estrutura Clara:** Organize a resposta com t√≥picos e subt√≥picos quando relevante
6. **Credibilidade:** Mencione dados espec√≠ficos e t√©cnicos encontrados nas fontes

**FORMATO DA RESPOSTA:**
- Comece com um resumo executivo
- Desenvolva os pontos t√©cnicos principais
- Inclua informa√ß√µes pr√°ticas espec√≠ficas
- Termine com recomenda√ß√µes ou conclus√µes

**N√ÉO APENAS CITE AS FONTES - ANALISE E SINTETIZE O CONTE√öDO REAL!**

Resposta t√©cnica detalhada:"""

            response = client.text_generation(
                prompt,
                max_new_tokens=1500,  # Aumenta limite para respostas mais completas
                temperature=0.6,  # Diminui temperatura para respostas mais focadas
                return_full_text=False
            )
            
            ai_response = response.strip()
            
            # Adiciona resumo das fontes analisadas
            sources_summary = "\n\n" + "="*50 + "\n"
            sources_summary += "üìö **FONTES ANALISADAS E PROCESSADAS:**\n\n"
            
            for i, source in enumerate(content_sources, 1):
                word_count = len(source['content'].split())
                sources_summary += f"**{i}. {source['title']}**\n"
                sources_summary += f"   üìä Conte√∫do analisado: ~{word_count} palavras\n"
                sources_summary += f"   üîó URL: {source['url']}\n"
                if source['snippet']:
                    sources_summary += f"   üìù Resumo: {source['snippet'][:100]}...\n"
                sources_summary += "\n"
            
            sources_summary += f"üí° **Total:** {len(content_sources)} fontes com conte√∫do real analisado pela IA"
            
            final_response = f"üîç **AN√ÅLISE COMPLETA DA INTERNET - \"{original_query}\"**\n\n{ai_response}{sources_summary}"
            
            print(f"‚úÖ Resposta gerada com sucesso! {len(final_response)} caracteres")
            return final_response
            
    except Exception as e:
        print(f"‚ùå Erro ao gerar resposta com LLM: {e}")
    
    # Fallback melhorado: cria um resumo manual mais inteligente
    print("üîÑ Usando fallback para gerar resumo manual...")
    
    response = f"üîç **PESQUISA E AN√ÅLISE NA INTERNET - \"{original_query}\"**\n\n"
    response += f"üìä **Analisei {len(content_sources)} fontes com conte√∫do real:**\n\n"
    
    # Cria resumo mais inteligente do conte√∫do
    for i, source in enumerate(content_sources, 1):
        response += f"**üìñ Fonte {i}: {source['title']}**\n"
        
        # Extrai trechos mais relevantes do conte√∫do
        content_words = source['content'].split()
        if len(content_words) > 50:
            # Pega primeiras e √∫ltimas partes para melhor contexto
            summary_start = ' '.join(content_words[:30])
            summary_end = ' '.join(content_words[-20:])
            content_summary = f"{summary_start}... {summary_end}"
        else:
            content_summary = source['content']
        
        response += f"üìã **Conte√∫do analisado:** {content_summary[:300]}...\n"
        response += f"üîó **Link:** {source['url']}\n\n"
    
    response += "üí° **IMPORTANTE:** Esta an√°lise foi baseada no conte√∫do REAL extra√≠do dos sites, n√£o apenas nos t√≠tulos ou links!"
    
    return response

# --- FUN√á√ïES DE PROCESSAMENTO ---
def get_text_client():
    """Cria e retorna um cliente para o modelo de linguagem."""
    if not HUGGING_FACE_TOKEN or not InferenceClient:
        return None
    return InferenceClient(model="meta-llama/Meta-Llama-3-8B-Instruct", token=HUGGING_FACE_TOKEN)

def get_vision_client():
    """Cria e retorna um cliente para an√°lise de imagens."""
    if not HUGGING_FACE_TOKEN or not InferenceClient:
        return None
    return InferenceClient(model="microsoft/kosmos-2-patch14-224", token=HUGGING_FACE_TOKEN)

def analyze_image(image_path):
    """Analisa uma imagem com m√∫ltiplos m√©todos para m√°xima precis√£o."""
    try:
        print(f"üñºÔ∏è Iniciando an√°lise completa da imagem: {os.path.basename(image_path)}")
        
        # 1. AN√ÅLISE VISUAL COM IA AVAN√áADA
        vision_analysis = ""
        detailed_analysis = ""
        
        try:
            client = get_vision_client()
            if client and HUGGING_FACE_TOKEN:
                print("ü§ñ Tentando an√°lise visual com IA...")
                
                # Prepara a imagem otimizada
                with open(image_path, 'rb') as f:
                    image_data = f.read()
                
                img = Image.open(io.BytesIO(image_data))
                original_size = img.size
                
                # Otimiza a imagem para melhor an√°lise
                if img.width > 1024 or img.height > 1024:
                    img.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
                
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # Melhora a qualidade da imagem para an√°lise
                from PIL import ImageEnhance
                enhancer = ImageEnhance.Contrast(img)
                img = enhancer.enhance(1.2)  # Aumenta contraste
                
                enhancer = ImageEnhance.Sharpness(img)
                img = enhancer.enhance(1.1)  # Aumenta nitidez
                
                # Salva em alta qualidade
                temp_buffer = io.BytesIO()
                img.save(temp_buffer, format='JPEG', quality=95, optimize=True)
                temp_buffer.seek(0)
                
                # M√∫ltiplas tentativas com diferentes modelos/configura√ß√µes
                vision_models = [
                    "microsoft/kosmos-2-patch14-224",
                    "Salesforce/blip-image-captioning-large",
                    "nlpconnect/vit-gpt2-image-captioning"
                ]
                
                for model_name in vision_models:
                    try:
                        print(f"üîç Testando modelo: {model_name}")
                        vision_client = InferenceClient(model=model_name, token=HUGGING_FACE_TOKEN)
                        
                        temp_buffer.seek(0)
                        result = vision_client.image_to_text(temp_buffer.getvalue())
                        
                        if result:
                            if isinstance(result, dict):
                                vision_analysis = result.get('generated_text', '')
                            else:
                                vision_analysis = str(result)
                            
                            if len(vision_analysis) > 20:  # Se obteve an√°lise √∫til
                                print(f"‚úÖ An√°lise visual obtida com {model_name}")
                                break
                                
                    except Exception as e:
                        print(f"‚ùå Modelo {model_name} falhou: {e}")
                        continue
                
                # Se conseguiu an√°lise visual, faz an√°lise mais detalhada
                if vision_analysis and len(vision_analysis) > 20:
                    try:
                        text_client = get_text_client()
                        if text_client:
                            enhancement_prompt = f"""Como especialista em manuten√ß√£o industrial, analise esta descri√ß√£o visual de uma imagem e forne√ßa uma interpreta√ß√£o t√©cnica detalhada:

DESCRI√á√ÉO VISUAL: {vision_analysis}

Forne√ßa uma an√°lise t√©cnica focada em:
1. Identifica√ß√£o de equipamentos/componentes
2. Estado/condi√ß√£o dos equipamentos
3. Poss√≠veis problemas ou anomalias
4. Recomenda√ß√µes de manuten√ß√£o
5. Aspectos de seguran√ßa

Seja espec√≠fico e t√©cnico:"""

                            enhanced_result = text_client.text_generation(
                                enhancement_prompt,
                                max_new_tokens=800,
                                temperature=0.6,
                                return_full_text=False
                            )
                            
                            detailed_analysis = enhanced_result.strip()
                            print("‚úÖ An√°lise t√©cnica detalhada gerada")
                            
                    except Exception as e:
                        print(f"‚ö†Ô∏è Erro na an√°lise detalhada: {e}")
                        
        except Exception as e:
            print(f"‚ùå Erro no sistema de vis√£o: {e}")
            vision_analysis = ""
        
        # 2. AN√ÅLISE T√âCNICA E METADADOS DA IMAGEM
        with open(image_path, 'rb') as f:
            image_data = f.read()
        
        img = Image.open(io.BytesIO(image_data))
        width, height = img.size
        format_img = img.format or "Desconhecido"
        
        print(f"üìä Analisando caracter√≠sticas da imagem {width}x{height}")
        
        # 3. AN√ÅLISE AVAN√áADA DE CARACTER√çSTICAS VISUAIS
        visual_characteristics = analyze_visual_characteristics(img)
        color_analysis = analyze_image_colors(img)
        
        # 4. AN√ÅLISE DO CONTEXTO DO ARQUIVO
        filename = os.path.basename(image_path).lower()
        context_hints = analyze_filename_context(filename)
        
        # 5. AN√ÅLISE DE METADADOS EXIF (se dispon√≠vel)
        metadata_info = extract_image_metadata(image_path)
        
        # 6. MONTA A RESPOSTA COMPLETA E INTELIGENTE
        if vision_analysis and len(vision_analysis) > 20:
            # Resposta completa com IA
            description = f"""üîç **AN√ÅLISE COMPLETA DA IMAGEM**

ü§ñ **VIS√ÉO COMPUTACIONAL - O que a IA identificou:**
{vision_analysis}

üîß **AN√ÅLISE T√âCNICA AEMI:**"""
            
            if detailed_analysis:
                description += f"\n{detailed_analysis}"
            else:
                description += f"\n{interpret_for_maintenance(vision_analysis)}"
            
            description += f"""

üìä **DADOS T√âCNICOS:**
‚Ä¢ Formato: {format_img} | Resolu√ß√£o: {width}x{height}px
‚Ä¢ Tamanho do arquivo: {len(image_data)/1024:.1f} KB
{visual_characteristics}
{color_analysis}
{context_hints}
{metadata_info}

üî¨ **CAPACIDADES DE AN√ÅLISE ATIVADAS:**
‚úÖ An√°lise visual com IA
‚úÖ Reconhecimento de equipamentos
‚úÖ Detec√ß√£o de anomalias
‚úÖ An√°lise de cores e texturas
‚úÖ Contextualiza√ß√£o industrial

üí¨ **PR√ìXIMOS PASSOS:**
Agora posso responder perguntas espec√≠ficas como:
‚Ä¢ "Que tipo de falha voc√™ identifica?"
‚Ä¢ "Quais os procedimentos de manuten√ß√£o?"
‚Ä¢ "Este equipamento est√° em bom estado?"
‚Ä¢ "Que ferramentas s√£o necess√°rias?"

‚ùì **Sua pergunta:** O que voc√™ gostaria de saber sobre esta imagem?"""

        elif vision_analysis and len(vision_analysis) > 5:
            # An√°lise b√°sica
            description = f"""üîç **AN√ÅLISE DA IMAGEM**

ü§ñ **An√°lise Visual B√°sica:**
{vision_analysis}

üîß **Interpreta√ß√£o T√©cnica:**
{interpret_for_maintenance(vision_analysis)}

üìä **Informa√ß√µes T√©cnicas:**
‚Ä¢ Formato: {format_img} | Dimens√µes: {width}x{height}px
‚Ä¢ Tamanho: {len(image_data)/1024:.1f} KB
{visual_characteristics}
{color_analysis}
{context_hints}

üí° **Como posso ajudar mais:**
Descreva sua d√∫vida espec√≠fica sobre a imagem para uma an√°lise mais direcionada."""

        else:
            # Fallback robusto com an√°lise alternativa
            description = f"""üì∏ **AN√ÅLISE DA IMAGEM (Modo Alternativo)**

‚ö†Ô∏è **Status da An√°lise Visual:**
A an√°lise autom√°tica com IA n√£o est√° dispon√≠vel no momento, mas posso ajudar de outras formas:

üîß **AN√ÅLISE BASEADA EM CARACTER√çSTICAS:**
{visual_characteristics}
{color_analysis}
{context_hints}
{metadata_info}

üìä **Dados T√©cnicos:**
‚Ä¢ Formato: {format_img} | Resolu√ß√£o: {width}x{height}px  
‚Ä¢ Tamanho: {len(image_data)/1024:.1f} KB

üéØ **COMO POSSO AJUDAR:**
Mesmo sem an√°lise visual autom√°tica, sou especialista em:
‚Ä¢ Procedimentos de manuten√ß√£o para equipamentos espec√≠ficos
‚Ä¢ An√°lise de falhas com base em sua descri√ß√£o
‚Ä¢ Recomenda√ß√µes de ferramentas e m√©todos
‚Ä¢ Normas de seguran√ßa industrial
‚Ä¢ Especifica√ß√µes t√©cnicas

üìù **Para melhor ajuda, me informe:**
1. Que equipamento/componente voc√™ v√™ na imagem?
2. Qual problema ou d√∫vida voc√™ tem?
3. Que tipo de an√°lise precisa?

üí¨ **Exemplo:** "Vejo um motor el√©trico com ru√≠do anormal" ou "Rolamento apresentando desgaste unusual\""""

        print("‚úÖ An√°lise completa da imagem finalizada")
        return description
        
    except Exception as e:
        error_msg = f"‚ùå Erro ao analisar imagem: {str(e)}"
        print(error_msg)
        return f"""{error_msg}

üîÑ **Solu√ß√µes poss√≠veis:**
‚Ä¢ Verifique se o arquivo n√£o est√° corrompido
‚Ä¢ Tente enviar em formato JPG ou PNG
‚Ä¢ Reduza o tamanho da imagem se for muito grande

üí¨ **Alternativa:** Descreva o que voc√™ v√™ na imagem e eu posso ajudar com base na descri√ß√£o!"""

def analyze_visual_characteristics(img):
    """Analisa caracter√≠sticas visuais b√°sicas da imagem."""
    try:
        # An√°lise de cores
        colors = img.getcolors(maxcolors=256*256*256)
        if colors:
            dominant_colors = sorted(colors, key=lambda x: x[0], reverse=True)[:3]
            
            # Interpreta√ß√£o das cores para contexto industrial
            color_hints = []
            for count, color in dominant_colors:
                if isinstance(color, tuple) and len(color) >= 3:
                    r, g, b = color[:3]
                    if r > 200 and g < 100 and b < 100:  # Vermelho
                        color_hints.append("Poss√≠vel indica√ß√£o de perigo/parada")
                    elif r > 200 and g > 200 and b < 100:  # Amarelo
                        color_hints.append("Poss√≠vel sinaliza√ß√£o de aten√ß√£o")
                    elif r < 100 and g > 150 and b < 100:  # Verde
                        color_hints.append("Poss√≠vel indica√ß√£o de funcionamento normal")
                    elif r < 100 and g < 100 and b > 150:  # Azul
                        color_hints.append("Poss√≠vel componente hidr√°ulico")
            
            if color_hints:
                return f"\nüé® **Indica√ß√µes visuais:** {', '.join(color_hints)}"
        
        return "\nüé® **An√°lise de cores:** Variadas (equipamento/ambiente industrial)"
    except:
        return ""

def analyze_filename_context(filename):
    """Analisa o nome do arquivo para contexto industrial."""
    maintenance_keywords = {
        'motor': 'Motor el√©trico/mec√¢nico',
        'rolamento': 'Rolamento/bearing',
        'bearing': 'Rolamento',
        'engrenagem': 'Sistema de engrenagens',
        'gear': 'Engrenagem',
        'bomba': 'Bomba hidr√°ulica/pneum√°tica',
        'pump': 'Bomba',
        'valvula': 'V√°lvula',
        'valve': 'V√°lvula',
        'correia': 'Correia/belt',
        'belt': 'Correia',
        'polia': 'Polia',
        'pulley': 'Polia',
        'falha': 'An√°lise de falha',
        'failure': 'Falha',
        'desgaste': 'Desgaste',
        'wear': 'Desgaste',
        'manutencao': 'Manuten√ß√£o',
        'maintenance': 'Manuten√ß√£o',
        'hidraulica': 'Sistema hidr√°ulico',
        'hydraulic': 'Hidr√°ulico',
        'pneumatic': 'Pneum√°tico',
        'pneumatica': 'Pneum√°tico',
        'eletrica': 'Sistema el√©trico',
        'electric': 'El√©trico',
        'sensor': 'Sensor/instrumento',
        'temperatura': 'Monitoramento t√©rmico',
        'pressure': 'Sistema de press√£o',
        'pressao': 'Sistema de press√£o',
        'vibration': 'An√°lise de vibra√ß√£o',
        'vibracao': 'An√°lise de vibra√ß√£o'
    }
    
    found = []
    for keyword, description in maintenance_keywords.items():
        if keyword in filename:
            found.append(description)
    
    if found:
        return f"\nüè∑Ô∏è **Contexto identificado:** {', '.join(found)}"
    return ""

def analyze_image_colors(img):
    """Analisa as cores da imagem para contexto industrial."""
    try:
        # Converte para RGB se necess√°rio
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # Redimensiona para an√°lise mais r√°pida
        img_small = img.resize((100, 100))
        
        # Obt√©m cores dominantes
        colors = img_small.getcolors(maxcolors=256*256*256)
        if not colors:
            return ""
        
        # Ordena por frequ√™ncia
        dominant_colors = sorted(colors, key=lambda x: x[0], reverse=True)[:5]
        
        color_interpretations = []
        for count, color in dominant_colors:
            if isinstance(color, tuple) and len(color) >= 3:
                r, g, b = color[:3]
                
                # Interpreta√ß√£o industrial das cores
                if r > 180 and g < 80 and b < 80:  # Vermelho forte
                    color_interpretations.append("üî¥ Vermelho predominante (indica√ß√£o de perigo/parada)")
                elif r > 200 and g > 150 and b < 100:  # Amarelo/laranja
                    color_interpretations.append("üü° Amarelo/laranja (sinaliza√ß√£o de aten√ß√£o)")
                elif r < 100 and g > 120 and b < 100:  # Verde
                    color_interpretations.append("üü¢ Verde detectado (opera√ß√£o normal)")
                elif r < 100 and g < 100 and b > 120:  # Azul
                    color_interpretations.append("üîµ Azul presente (sistemas hidr√°ulicos)")
                elif r > 150 and g > 100 and b < 80:  # Marrom/ferrugem
                    color_interpretations.append("üü§ Tons marrons (poss√≠vel oxida√ß√£o)")
                elif r > 120 and g > 120 and b > 120:  # Tons met√°licos
                    color_interpretations.append("‚ö™ Tons met√°licos (estruturas/equipamentos)")
        
        if color_interpretations:
            return f"\nüé® **An√°lise de cores:** {'; '.join(color_interpretations[:3])}"
        return ""
        
    except Exception as e:
        print(f"Erro na an√°lise de cores: {e}")
        return ""

def extract_image_metadata(image_path):
    """Extrai metadados EXIF da imagem quando dispon√≠vel."""
    try:
        from PIL.ExifTags import TAGS
        
        img = Image.open(image_path)
        
        if hasattr(img, '_getexif'):
            exifdata = img.getexif()
            
            if exifdata:
                metadata = []
                for tag_id in exifdata:
                    tag = TAGS.get(tag_id, tag_id)
                    data = exifdata.get(tag_id)
                    
                    if tag in ['DateTime', 'DateTimeOriginal']:
                        metadata.append(f"üìÖ Data: {data}")
                    elif tag == 'Make':
                        metadata.append(f"üì± Dispositivo: {data}")
                    elif tag == 'Software':
                        metadata.append(f"üíª Software: {data}")
                
                if metadata:
                    return f"\nüìã **Metadados:** {'; '.join(metadata[:2])}"
        
        return ""
        
    except Exception:
        return ""

def interpret_for_maintenance(vision_text):
    """Interpreta a an√°lise visual no contexto de manuten√ß√£o industrial."""
    vision_lower = vision_text.lower()
    
    interpretations = []
    
    # Identifica equipamentos
    if any(word in vision_lower for word in ['motor', 'engine', 'm√°quina', 'machine']):
        interpretations.append("üîß **Motor/M√°quina identificado** - Posso ajudar com an√°lise de vibra√ß√£o, alinhamento, lubrifica√ß√£o")
    
    if any(word in vision_lower for word in ['rolamento', 'bearing', 'roda', 'wheel']):
        interpretations.append("‚öôÔ∏è **Rolamento detectado** - Posso orientar sobre montagem, desmontagem e an√°lise de falhas")
    
    if any(word in vision_lower for word in ['tubo', 'pipe', 'mangueira', 'hose']):
        interpretations.append("üîß **Sistema hidr√°ulico/pneum√°tico** - Posso ajudar com press√µes, veda√ß√µes e conex√µes")
    
    if any(word in vision_lower for word in ['parafuso', 'bolt', 'rosca', 'thread']):
        interpretations.append("üî© **Fixa√ß√£o detectada** - Posso orientar sobre torques e procedimentos de aperto")
    
    if any(word in vision_lower for word in ['√≥leo', 'oil', 'graxa', 'grease', 'lubrificante']):
        interpretations.append("üõ¢Ô∏è **Lubrifica√ß√£o identificada** - Posso ajudar com intervalos e tipos de lubrificantes")
    
    # Identifica problemas
    if any(word in vision_lower for word in ['rachadura', 'crack', 'quebrado', 'broken']):
        interpretations.append("‚ö†Ô∏è **Poss√≠vel falha estrutural** - Recomendo inspe√ß√£o detalhada e avalia√ß√£o de seguran√ßa")
    
    if any(word in vision_lower for word in ['oxida√ß√£o', 'rust', 'corros√£o', 'corrosion']):
        interpretations.append("üî¥ **Corros√£o detectada** - Posso orientar sobre tratamento e preven√ß√£o")
    
    if any(word in vision_lower for word in ['desgaste', 'wear', 'gasto', 'worn']):
        interpretations.append("üìâ **Desgaste identificado** - Posso ajudar a avaliar vida √∫til restante")
    
    if interpretations:
        return '\n'.join(interpretations)
    else:
        return "üìã **An√°lise geral:** Identifiquei elementos industriais. Me descreva sua d√∫vida espec√≠fica para orienta√ß√£o detalhada."

def generate_chat_response(chat_history):
    """Processa um hist√≥rico de chat e retorna a resposta do modelo."""
    client = get_text_client()
    if not client:
        return "Desculpe, o servi√ßo de IA n√£o est√° dispon√≠vel no momento."
    
    try:
        response_generator = client.chat_completion(
            messages=chat_history,
            max_tokens=1500,
            stream=False
        )
        return response_generator.choices[0].message.content
    except Exception as e:
        print(f"Erro na gera√ß√£o de resposta: {e}")
        return "Desculpe, ocorreu um erro ao gerar a resposta."

# --- ROTAS PRINCIPAIS ---
@app.route('/')
def index():
    return "Servidor da AEMI (vers√£o com Llama 3 8B e mem√≥ria) est√° no ar."

@app.route('/chat', methods=['POST'])
def chat():
    try:
        user_message = request.form.get('message', '')
        if not user_message.strip():
            return jsonify({"error": "Nenhuma mensagem enviada."}), 400

        # 1. Buscar resposta na base de conhecimento
        kb = load_kb()
        user_message_lower = user_message.lower()
        import difflib
        
        # Busca exata ou substring em FAQ
        for item in kb:
            if item['type'] == 'faq' and user_message_lower in item.get('content','').lower():
                return jsonify({'response': f"[Base de Conhecimento]\n{item['content'][:600]}"})
        
        # Busca fuzzy em FAQ
        best_match = None
        best_ratio = 0.0
        for item in kb:
            if item['type'] == 'faq':
                content = item.get('content','').lower()
                ratio = difflib.SequenceMatcher(None, user_message_lower, content).ratio()
                if ratio > best_ratio:
                    best_ratio = ratio
                    best_match = item
        
        if best_match and best_ratio > 0.45:
            return jsonify({'response': f"[Base de Conhecimento - resposta aproximada]\n{best_match['content'][:600]}"})

        # 2. Buscar por conte√∫do extra√≠do de arquivos
        for item in kb:
            if item['type'] == 'file' and item.get('content') and user_message_lower in item['content'].lower():
                return jsonify({'response': f"[Arquivo: {item['name']}]\n{item['content'][:600]}..."})
        
        # Busca fuzzy no conte√∫do de arquivos
        best_file_match = None
        best_file_ratio = 0.0
        for item in kb:
            if item['type'] == 'file' and item.get('content'):
                content = item['content'].lower()
                ratio = difflib.SequenceMatcher(None, user_message_lower, content).ratio()
                if ratio > best_file_ratio:
                    best_file_ratio = ratio
                    best_file_match = item
        
        if best_file_match and best_file_ratio > 0.45:
            return jsonify({'response': f"[Arquivo (aprox.): {best_file_match['name']}]\n{best_file_match['content'][:600]}..."})

        # 3. Buscar por nome de arquivo/documento
        for item in kb:
            if item['type'] == 'file' and user_message_lower in item.get('name','').lower():
                return jsonify({'response': f"Encontrei um documento relacionado: {item['name']}\nClique para baixar: /kb/download/{item['id']}"})
        
        # Fuzzy para nome de arquivo
        best_file = None
        best_file_ratio = 0.0
        for item in kb:
            if item['type'] == 'file':
                name = item.get('name','').lower()
                ratio = difflib.SequenceMatcher(None, user_message_lower, name).ratio()
                if ratio > best_file_ratio:
                    best_file_ratio = ratio
                    best_file = item
        
        if best_file and best_file_ratio > 0.45:
            return jsonify({'response': f"Encontrei um documento relacionado: {best_file['name']}\nClique para baixar: /kb/download/{best_file['id']}"})

        # 4. Verificar se precisa de pesquisa na internet
        if should_search_internet(user_message):
            print(f"Realizando pesquisa na internet para: {user_message}")
            search_results = search_internet(user_message, max_results=5)
            analyzed_results = analyze_search_content(search_results, user_message)
            
            # Se encontrou e analisou resultados, retorna eles
            if "results" in search_results and search_results["results"]:
                return jsonify({"response": analyzed_results})
            
            # Se n√£o encontrou, continua para o LLM com uma nota sobre a pesquisa
            user_message += " (Pesquisa na internet n√£o retornou resultados √∫teis)"
        
        # 5. Se n√£o encontrou na KB nem precisou pesquisar, usar o LLM
        if 'chat_history' not in session:
            session['chat_history'] = [{"role": "system", "content": SYSTEM_PROMPT}]
        
        # Verifica se h√° conte√∫do de arquivo enviado para incluir na an√°lise
        enhanced_message = user_message
        if 'uploaded_file_content' in session and session['uploaded_file_content']:
            file_data = session['uploaded_file_content']
            
            # Cria contexto baseado no tipo de an√°lise
            if file_data.get('analysis_type') == 'visual':
                enhanced_message = f"""Como A.E.M.I, especialista em manuten√ß√£o industrial, analise esta imagem e responda: {user_message}

üì∏ **Arquivo de Imagem:** {file_data['filename']}
üîç **An√°lise Visual Completa:**
{file_data['content']}

**Instru√ß√µes:**
- Responda com base na an√°lise visual da imagem
- Foque em aspectos de manuten√ß√£o industrial
- Seja t√©cnica e detalhada
- Se identificar problemas, sugira solu√ß√µes"""
            
            elif file_data.get('analysis_type') == 'text':
                enhanced_message = f"""Como A.E.M.I, especialista em manuten√ß√£o industrial, analise este documento e responda: {user_message}

üìÑ **Documento:** {file_data['filename']} (tipo: {file_data['type']})

**Conte√∫do do Documento:**
{file_data['content']}

**Instru√ß√µes:**
- Analise o conte√∫do do documento em detalhes
- Responda √† pergunta com base nas informa√ß√µes do arquivo
- Seja espec√≠fica e t√©cnica
- Cite trechos relevantes do documento quando apropriado"""
            
            else:
                enhanced_message = f"""Pergunta sobre o arquivo enviado: {user_message}

Arquivo: {file_data['filename']} (tipo: {file_data['type']})

Conte√∫do do arquivo:
{file_data['content']}

Instru√ß√µes: Analise o conte√∫do do arquivo e responda √† pergunta do usu√°rio com base nessas informa√ß√µes."""
        
        session['chat_history'].append({"role": "user", "content": enhanced_message})
        
        if len(session['chat_history']) > MAX_HISTORY_LENGTH:
            session['chat_history'] = [session['chat_history'][0]] + session['chat_history'][-MAX_HISTORY_LENGTH:]
        
        print(f"Processando com hist√≥rico de {len(session['chat_history'])} mensagens...")
        bot_response = generate_chat_response(session['chat_history'])
        
        session['chat_history'].append({"role": "assistant", "content": bot_response})
        session.modified = True
        
        print("Resposta da IA gerada e hist√≥rico atualizado.")
        return jsonify({"response": bot_response})

    except Exception as e:
        print(f"ERRO GERAL na rota /chat: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": f"Ocorreu um erro inesperado no servidor. Detalhes: {str(e)}"}), 500

@app.route('/upload-file', methods=['POST'])
def upload_file():
    """Upload de arquivo para an√°lise no chat."""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'Nenhum arquivo enviado'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'Nenhum arquivo selecionado'}), 400
        
        # Salva o arquivo temporariamente
        file_id = str(uuid.uuid4())
        ext = os.path.splitext(file.filename)[1].lower()
        filename = f"{file_id}{ext}"
        temp_path = os.path.join(KB_DIR, filename)
        file.save(temp_path)
        
        # Analisa o arquivo baseado no tipo
        response_text = ""
        file_content = ""
        
        # Verifica se √© imagem
        if ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']:
            response_text = "üì∏ **ARQUIVO RECEBIDO, NO QUE POSSO AJUDAR?**"
            
            # An√°lise visual da imagem
            try:
                visual_analysis = analyze_image(temp_path)
                if visual_analysis:
                    # Salva an√°lise na sess√£o
                    session['uploaded_file_content'] = {
                        'filename': file.filename,
                        'type': 'image',
                        'content': visual_analysis,
                        'analysis_type': 'visual'
                    }
                    session.modified = True
            except Exception as e:
                print(f"Erro na an√°lise visual: {e}")
        
        # Verifica se √© PDF
        elif ext == '.pdf' and PyPDF2:
            response_text = "üìÑ **DOCUMENTO PDF RECEBIDO - ANALISANDO CONTE√öDO...**"
            
            try:
                print(f"üìÑ Processando PDF: {file.filename}")
                
                with open(temp_path, 'rb') as f:
                    reader = PyPDF2.PdfReader(f)
                    text_content = ""
                    pdf_info = {
                        'total_pages': len(reader.pages),
                        'processed_pages': 0,
                        'tables_found': 0,
                        'images_found': 0
                    }
                    
                    print(f"üìä PDF tem {pdf_info['total_pages']} p√°ginas")
                    
                    # Extrai texto de forma mais inteligente
                    pages_to_read = min(20, len(reader.pages))  # Aumenta para 20 p√°ginas
                    
                    for i in range(pages_to_read):
                        try:
                            page = reader.pages[i]
                            page_text = page.extract_text() or ''
                            
                            if len(page_text.strip()) > 50:  # S√≥ processa p√°ginas com conte√∫do substancial
                                # Limpa e formata o texto da p√°gina
                                cleaned_page = clean_pdf_text(page_text)
                                text_content += f"\n=== P√ÅGINA {i+1} ===\n{cleaned_page}\n"
                                pdf_info['processed_pages'] += 1
                                
                                # Detecta tabelas (texto com muitos espa√ßos/tabs)
                                if count_table_patterns(page_text) > 3:
                                    pdf_info['tables_found'] += 1
                                    
                        except Exception as e:
                            print(f"Erro na p√°gina {i+1}: {e}")
                            continue
                    
                    # Gera resumo inteligente do PDF
                    if text_content.strip():
                        pdf_summary = generate_pdf_summary(text_content, file.filename)
                        
                        full_content = f"""üìã **RESUMO DO DOCUMENTO:**
{pdf_summary}

üìä **ESTAT√çSTICAS DO PDF:**
‚Ä¢ Total de p√°ginas: {pdf_info['total_pages']}
‚Ä¢ P√°ginas processadas: {pdf_info['processed_pages']}
‚Ä¢ Tabelas detectadas: {pdf_info['tables_found']}
‚Ä¢ Tamanho do conte√∫do: ~{len(text_content.split())} palavras

üìÑ **CONTE√öDO COMPLETO EXTRA√çDO:**
{text_content[:20000]}"""  # Aumenta limite significativamente
                        
                        # Salva na sess√£o com an√°lise aprimorada
                        session['uploaded_file_content'] = {
                            'filename': file.filename,
                            'type': 'pdf',
                            'content': full_content,
                            'analysis_type': 'document',
                            'metadata': pdf_info
                        }
                        session.modified = True
                        
                        response_text = f"üìÑ **PDF PROCESSADO COM SUCESSO!**\n\n{pdf_summary}\n\nüí¨ **Agora voc√™ pode perguntar sobre qualquer aspecto do documento!**"
                        
                    else:
                        response_text = "üìÑ **PDF processado, mas pouco texto foi extra√≠do. Pode ser um documento com muitas imagens ou texto digitalizado.**"
                        
            except Exception as e:
                print(f"Erro ao processar PDF: {e}")
                response_text = f"‚ùå **Erro ao processar PDF:** {str(e)}\n\nüí° **Dica:** Verifique se o PDF n√£o est√° protegido ou corrompido."
        
        # Verifica se √© documento Word
        elif ext in ['.docx'] and docx:
            response_text = "üìÑ **ARQUIVO RECEBIDO, NO QUE POSSO AJUDAR?**"
            
            try:
                doc = docx.Document(temp_path)
                paragraphs = []
                
                # Extrai par√°grafos com formata√ß√£o
                for i, para in enumerate(doc.paragraphs):
                    if para.text.strip():
                        paragraphs.append(f"Par√°grafo {i+1}: {para.text.strip()}")
                
                text_content = '\n'.join(paragraphs[:30])  # Primeiros 30 par√°grafos
                
                # Salva na sess√£o
                session['uploaded_file_content'] = {
                    'filename': file.filename,
                    'type': 'docx',
                    'content': text_content[:15000],  # Aumenta limite
                    'analysis_type': 'text'
                }
                session.modified = True
            except Exception as e:
                print(f"Erro ao processar documento: {e}")
        
        # Arquivo de texto
        elif ext in ['.txt', '.md', '.csv']:
            response_text = "üìù **ARQUIVO RECEBIDO, NO QUE POSSO AJUDAR?**"
            
            try:
                with open(temp_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read(15000)  # Aumenta limite
                    
                    # Salva na sess√£o
                    session['uploaded_file_content'] = {
                        'filename': file.filename,
                        'type': ext,
                        'content': content,
                        'analysis_type': 'text'
                    }
                    session.modified = True
            except Exception as e:
                print(f"Erro ao processar arquivo: {e}")
        
        else:
            response_text = "üìé **ARQUIVO RECEBIDO, NO QUE POSSO AJUDAR?**"
        
        # Remove o arquivo tempor√°rio
        try:
            os.remove(temp_path)
        except:
            pass
        
        return jsonify({
            'response': response_text,
            'filename': file.filename,
            'file_type': ext
        })
    
    except Exception as e:
        print(f"Erro no upload de arquivo: {e}")
        return jsonify({'error': 'Erro ao processar arquivo'}), 500

@app.route('/search-internet', methods=['POST'])
def search_internet_route():
    """Rota para pesquisa manual na internet."""
    try:
        query = request.form.get('query', '').strip()
        if not query:
            return jsonify({"error": "Query de pesquisa n√£o fornecida"}), 400
        
        max_results = int(request.form.get('max_results', 5))
        search_results = search_internet(query, max_results)
        
        return jsonify(search_results)
    
    except Exception as e:
        print(f"Erro na pesquisa manual: {e}")
        return jsonify({"error": "Erro ao realizar pesquisa"}), 500

@app.route('/extract-content', methods=['POST'])
def extract_content_route():
    """Rota para extrair conte√∫do de uma URL."""
    try:
        url = request.form.get('url', '').strip()
        if not url:
            return jsonify({"error": "URL n√£o fornecida"}), 400
        
        max_chars = int(request.form.get('max_chars', 1000))
        content = extract_page_content(url, max_chars)
        
        return jsonify({"content": content, "url": url})
    
    except Exception as e:
        print(f"Erro na extra√ß√£o de conte√∫do: {e}")
        return jsonify({"error": "Erro ao extrair conte√∫do"}), 500

@app.route('/clear-session', methods=['POST'])
def clear_session():
    """Limpa o hist√≥rico de chat da sess√£o do usu√°rio."""
    try:
        if 'chat_history' in session:
            session.pop('chat_history', None)
            print("Sess√£o do usu√°rio limpa.")
        return jsonify({"status": "success", "message": "Hist√≥rico de chat limpo."})
    except Exception as e:
        print(f"Erro ao limpar sess√£o: {e}")
        return jsonify({"error": "Erro ao limpar sess√£o"}), 500

def clean_pdf_text(text):
    """Limpa e formata texto extra√≠do de PDF."""
    import re
    
    # Remove quebras de linha excessivas
    text = re.sub(r'\n\s*\n', '\n\n', text)
    
    # Remove espa√ßos m√∫ltiplos
    text = re.sub(r' +', ' ', text)
    
    # Remove caracteres especiais problem√°ticos
    text = re.sub(r'[^\w\s\.\,\;\:\!\?\-\(\)\[\]\"\'\/\%\$\@\#\&\*\+\=\~\`]', '', text)
    
    # Corrige quebras de linha no meio de palavras
    text = re.sub(r'(\w)-\s*\n\s*(\w)', r'\1\2', text)
    
    return text.strip()

def count_table_patterns(text):
    """Conta padr√µes que indicam presen√ßa de tabelas."""
    import re
    
    # Conta linhas com m√∫ltiplas sequ√™ncias de espa√ßos (indicativo de colunas)
    tab_patterns = len(re.findall(r'.*\s{3,}.*\s{3,}.*', text))
    
    # Conta linhas com n√∫meros seguidos de espa√ßos (t√≠pico de tabelas)
    num_patterns = len(re.findall(r'\d+\s+\d+', text))
    
    return tab_patterns + num_patterns

def generate_pdf_summary(content, filename):
    """Gera um resumo inteligente do conte√∫do do PDF."""
    try:
        client = get_text_client()
        if not client:
            return "Documento processado - conte√∫do dispon√≠vel para consulta."
        
        # Pega uma amostra representativa do conte√∫do
        content_sample = content[:8000]  # Primeiros 8000 caracteres
        
        summary_prompt = f"""Como A.E.M.I, especialista em manuten√ß√£o industrial, analise este documento PDF e forne√ßa um resumo t√©cnico detalhado:

ARQUIVO: {filename}

CONTE√öDO DO DOCUMENTO:
{content_sample}

INSTRU√á√ïES:
1. Identifique o tipo de documento (manual, norma, procedimento, etc.)
2. Liste os principais t√≥picos t√©cnicos abordados
3. Destaque informa√ß√µes relevantes para manuten√ß√£o industrial
4. Identifique especifica√ß√µes, procedimentos ou dados importantes
5. Seja conciso mas t√©cnico

FORMATO DO RESUMO:
üìã **Tipo de documento:** [tipo identificado]
üîß **Principais t√≥picos:** [lista dos principais assuntos]
‚öôÔ∏è **Aspectos t√©cnicos relevantes:** [informa√ß√µes t√©cnicas importantes]
üí° **Aplica√ß√£o pr√°tica:** [como usar este documento na manuten√ß√£o]

Resumo:"""

        response = client.text_generation(
            summary_prompt,
            max_new_tokens=800,
            temperature=0.5,
            return_full_text=False
        )
        
        return response.strip()
        
    except Exception as e:
        print(f"Erro ao gerar resumo: {e}")
        return f"üìÑ **Documento processado:** {filename}\n\nüîç **Conte√∫do dispon√≠vel para an√°lise** - Fa√ßa perguntas espec√≠ficas sobre o documento!"

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=True)
